Basic Idea for testing parsing section was to start with the commands that do not rely on the other commands eg VAR, OP etc. and then build the commands which use purely those and so on. Additionally I tried to first test each command by itself in its own struct before adding in other commands- so created a new struct to test POLISH, then a new struct for SET and so on. Was important to test the position that the functions move the struct to as well as this will be basis for how we move to next command.Using variables that haven't been set is not picked up in the parsing stage but will be in the interpreting stage.

For my black box testing of parser.c I have added in two commands to my makefile - run_parser_err which runs a series of invalid files and feeds the error messages into p_error.txt and run_parser_val which runs a series of valid files.

Additionally created each of the ADTS separately tested them by themselves in their own test file and then introduced them into the parsing/interpreting functions. 

For the interpreting section of the task testing a bit harder because a lot of it is outputing to SDL. Made sense to me to create a data structure that held all the points that were going to be fed to the SDL function so that these could be tested and checked. Another benefit of this is that we can separate out the SDL functions from our interpreter tests and check if any of our interpreter functions have memory leaks outside of SDL.  Same theory went into building and testing the functions - start from the functions that can work by themselves and can be tested easily and then work our way up to functions that rely on these ones etc.

For an example the order in which I created the first few main functions in interpreter went -

Rotate -no dependancies
get_num - dependancies from parser section 
Get_rotation - dependancy - get_num
move_forward - dependancies - get_num and rotate
do_instruction - dependancies get_rotation and move_forward

This allows for easier testing as we test each function thoroughly before moving onto the next so if there is a problem we do not have to dive deep into multiple layers of functions- instead abstracting away the complexities of rotating around a point or getting numbers as we go. This sort of permeates into how I set up my test files - basically split up the test files into smaller bits eg testing stacks or testing the functions part of my extension then mix different parts of the project together - not sure if its the most efficient way of testing but makes it clear what bit of the project you are testing at each stage and you can compartmentalise a lot easier. Also means you can focus on one specific part of the code at a time so makes spotting bugs and stuff easier. Only downside is it makes my makefile huge.


For the black box testing in regards to the interpreting stage I did a similar thing to the parsing stage where I threw a load of invalid inputs into the makefile and sent the outputs to i_error.txt. Added to this in turtle outputs you can see the output of different files - the name of the picture correlates to the file ran. I did the same thing for the extension as well.

Also not sure if this is the correct place to say this but I put functions that are specific to each part of the project into their own specific.c and specific.h along with struct definitions. This means that we can pretty much run any of the testing files with any version of the specific.c/h files. Pick'n'Mix testing.


Lastly for the extension I followed pretty much the same ideas as the interpreter - although I split up the extension into two parts, one for functions and one for control flow. This meant that I was able to test each part easily without worrying about their interactions first. 


